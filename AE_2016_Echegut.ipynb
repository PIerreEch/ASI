{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASI assessed exercise 2015/2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "#### Download the red and white wine .csv files and import them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "red_wine = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "white_wine = pd.read_csv('winequality-white.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "#### Plot bar-plots of the number of examples with each target value for the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "red_wine.groupby('quality').count()['fixed acidity'].plot(kind='bar')\n",
    "plt.xlabel(\"Target value\") \n",
    "plt.ylabel(\"Number\")\n",
    "plt.title('Figure 1: The number of examples for each target value for red wine')\n",
    "plt.grid(True,which=\"both\",ls=\"-\")\n",
    "plt.show()\n",
    "\n",
    "white_wine.groupby('quality').count()['fixed acidity'].plot(kind='bar')\n",
    "plt.xlabel(\"Target value\")\n",
    "plt.ylabel(\"Number\")\n",
    "plt.title('Figure 2: The number of examples for each target value for white wine')\n",
    "plt.grid(True,which=\"both\",ls=\"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "#### Comment on these distributions. How might they effect the analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This ditributions look a lot like normal distributions. The datas which have a quality of 5 6 and 7 will be easy to find because there is a lot of data in this range, but the datas with a quality of 3,4 or 8 will be harder to find."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 - Linear regression\n",
    "#### (a) We will now concentrate on the red wine data. Randomly split the data into a training and test set with 70% of the examples in the training and 30% in the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "splitData = int(70/100*len(red_wine))\n",
    "index = []\n",
    "for k in range(len(red_wine)):\n",
    "    index.append(k)\n",
    "random.shuffle(index)\n",
    "train_index = index[:splitData]\n",
    "test_index = index[splitData:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = red_wine.iloc[train_index].sort_index()\n",
    "test_data = red_wine.iloc[test_index].sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Fit a linear regression to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#create X\n",
    "X = np.eye(len(train_data), 12)\n",
    "for k in range(len(train_data)) :\n",
    "    X[k][0] = 1\n",
    "k=1\n",
    "train_index.sort()\n",
    "for column in train_data :\n",
    "    if column != 'quality' :\n",
    "        for line in range(len(train_data)):\n",
    "            X[line][k] = train_data[column][train_index[line]]\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create t\n",
    "t=np.eye(len(train_data), 1)\n",
    "for line in range(len(train_data)):\n",
    "            t[line][0] = train_data['quality'][train_index[line]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute w_hat\n",
    "w_hat = np.linalg.inv((X.transpose()).dot(X)).dot(X.transpose()).dot(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute the linear regression\n",
    "linreg = X.dot(w_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Make a scatter plot the predictions versus the true targets for the test set and compute the mean squared error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = np.eye(len(test_data), 12)\n",
    "for k in range(len(test_data)) :\n",
    "    X_test[k][0] = 1\n",
    "k=1\n",
    "test_index.sort()\n",
    "for column in test_data :\n",
    "    if column != 'quality' :\n",
    "        for line in range(len(test_data)):\n",
    "            X_test[line][k] = test_data[column][test_index[line]]\n",
    "        k=k+1\n",
    "t_test=np.eye(len(test_data), 1)\n",
    "for line in range(len(test_data)):\n",
    "            t_test[line][0] = test_data['quality'][test_index[line]]\n",
    "value_test = X_test.dot(w_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEKCAYAAAAb7IIBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7b94950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlim(3, 8)\n",
    "plt.ylim(0,10)\n",
    "plt.plot(value_test,t_test,'o', alpha = 0.2)\n",
    "plt.plot(linreg,linreg)\n",
    "plt.ylabel('Quality')\n",
    "plt.title('Predicton versus the true target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean squarred error is : 0.390235248522\n"
     ]
    }
   ],
   "source": [
    "EMS = ((value_test - t_test)**2).mean()\n",
    "print(\"The mean squarred error is :\",EMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Suggest a benchmark that you could use to decide if this mean squared error value is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can compare this mean square error to the mean square error with an other method. One method which can be used is to make the matrix X with the same column but with different factors, with X=[1,x,x^2,x^3...]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Implement your benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def benchmark(column,K) :\n",
    "    X = np.eye(len(train_data), K)\n",
    "    for k in range(len(train_data)) :\n",
    "        X[k][0] = 1\n",
    "    train_index.sort()\n",
    "    for k in range(1,K) :\n",
    "        for line in range(len(train_data)) :\n",
    "            X[line][k] = train_data[column][train_index[line]]**k\n",
    "        \n",
    "    t=np.eye(len(train_data), 1)\n",
    "    for line in range(len(train_data)):\n",
    "            t[line][0] = train_data['quality'][train_index[line]]\n",
    "            \n",
    "    w_hat = np.linalg.inv((X.transpose()).dot(X)).dot(X.transpose()).dot(t)\n",
    "    \n",
    "    linreg = X.dot(w_hat)\n",
    "    \n",
    "    X_test = np.eye(len(test_data), K)\n",
    "    for k in range(len(test_data)) :\n",
    "        X_test[k][0] = 1\n",
    "    k=1\n",
    "    test_index.sort()\n",
    "    for k in range(1,K) :\n",
    "        for line in range(len(test_data)) :\n",
    "            X_test[line][k] = test_data[column][test_index[line]]**k\n",
    "            \n",
    "    t_test=np.eye(len(test_data), 1)\n",
    "    for line in range(len(test_data)):\n",
    "                t_test[line][0] = test_data['quality'][test_index[line]]\n",
    "    value_test = X_test.dot(w_hat)\n",
    "    \n",
    "    EMS = ((value_test - t_test)**2).mean()\n",
    "    #print(\"The mean squarred error is :\")\n",
    "    return EMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With the best K and the best column, the mean square error is : 0.481972133329\n"
     ]
    }
   ],
   "source": [
    "benchmark_value = [min([benchmark(column,k) for k in range(1,6)]) for column in ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\n",
    "b=min(benchmark_value)\n",
    "print(\"With the best K and the best column, the mean square error is :\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Briefly discuss the linear regression performance with respect to the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Even if we use the best column and the best K, the mean square error of the benchmark is still a lot higher than if we use all the column in the same time - around 20 percent higher in some cases. So the linear regression performance is good compared to my benchmark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5 - Regularized linear regression\n",
    "#### (a) Implement regularized least squares and make a plot of the test performance versus the regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.eye(12, 12)\n",
    "A[0][0] = 0\n",
    "def RLS(l) :\n",
    "    theta = np.linalg.inv((X.transpose()).dot(X)-l*A).dot(X.transpose()).dot(t)\n",
    "    value = X_test.dot(theta)\n",
    "    EMS = ((value - t_test)**2).mean()\n",
    "    return EMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xabfd7b0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEPCAYAAABhkeIdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa160850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"Regularization parameter (x0.01)\")\n",
    "plt.ylabel(\"Test performance\")\n",
    "plt.plot([RLS(0.01*l) for l in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Describe why this is not a good way of determining the value of the regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is not a good idea because we search it only for one test data, indeed, it would be better to do the same thing with different test and training data. That's why we should do an n-fold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  (c) Implement a 10-fold CV on the training data and use this to determine the value of the regularization parameter. Quote the optimal value, and the performance at this value on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It splits the train data to allow to take a part as train or test data for the CV\n",
    "index = [k for k in range(len(train_data))]\n",
    "random.shuffle(index)\n",
    "size = int(len(index)/10)\n",
    "train_split = []\n",
    "trainCV = []\n",
    "for k in range (9) :\n",
    "    split = []\n",
    "    for r in range(k*size,k*size+size):\n",
    "        split.append(index[r])\n",
    "    train_split.append(split)\n",
    "split = []\n",
    "for r in range(9*size, len(index)):\n",
    "    split.append(index[r])\n",
    "train_split.append(split)\n",
    "\n",
    "for k in range(10) :\n",
    "    trainCV.append(train_data.iloc[train_split[k]].sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choose_train is the function that chooses which part of the train data will be the train data or the test data for the CV\n",
    "def choose_train(k) :\n",
    "    train_datas = []\n",
    "    test_datas = []\n",
    "    for r in range(10) :\n",
    "        if r!=k :\n",
    "            train_datas = train_datas + train_split[r]\n",
    "    train_datas.sort()\n",
    "    test_datas = train_split[k]\n",
    "    test_datas.sort()\n",
    "    trainCV = train_data.iloc[train_datas].sort_index()\n",
    "    testCV = train_data.iloc[test_datas].sort_index()\n",
    "    return [trainCV,testCV,train_datas,test_datas]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train is the function that create the linear regression on the train data for the CV\n",
    "def train(k) :\n",
    "    [train_datas, test_datas, train_indexes,test_indexes] = choose_train(k)\n",
    "    XCV = np.eye(len(train_datas), 12)\n",
    "    for k in range(len(train_datas)) :\n",
    "        XCV[k][0] = 1\n",
    "    k=0\n",
    "    \n",
    "    for j in train_indexes :\n",
    "        train_indexes[k] = train_datas.iloc[k].name\n",
    "        k=k+1\n",
    "    k=1\n",
    "    for column in train_datas :\n",
    "        if column != 'quality' :\n",
    "            for line in range(len(train_datas)):\n",
    "                XCV[line][k] = train_datas[column][train_indexes[line]]\n",
    "            k=k+1\n",
    "                        \n",
    "    tCV=np.eye(len(train_datas), 1)\n",
    "    for line in range(len(train_datas)):\n",
    "            tCV[line][0] = train_datas['quality'][train_indexes[line]]\n",
    "                        \n",
    "    w_hatCV = np.linalg.inv((XCV.transpose()).dot(XCV)).dot(XCV.transpose()).dot(tCV)\n",
    "    \n",
    "    linregCV = XCV.dot(w_hatCV)\n",
    "    \n",
    "    return [linregCV,w_hatCV,XCV,tCV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test is the function that computes the data needed from the test data\n",
    "def test(k) :\n",
    "    [train_datas, test_datas, train_indexes,test_indexes] = choose_train(k)\n",
    "    [a,b,c,d] = train(k)\n",
    "    XCV_test = np.eye(len(test_datas), 12)\n",
    "    for k in range(len(test_datas)) :\n",
    "        XCV_test[k][0] = 1\n",
    "    k=0\n",
    "    test_indexes2 = []\n",
    "    for j in test_indexes :\n",
    "        test_indexes2.append(test_datas.iloc[k].name)\n",
    "        k=k+1\n",
    "    k=1\n",
    "    for column in train_datas :\n",
    "        if column != 'quality' :\n",
    "            for line in range(len(test_datas)):\n",
    "                XCV_test[line][k] = test_datas[column][test_indexes2[line]]\n",
    "            k = k+1\n",
    "            \n",
    "    tCV_test=np.eye(len(test_datas), 1)\n",
    "    for line in range(len(test_datas)):\n",
    "                tCV_test[line][0] = test_datas['quality'][test_indexes2[line]]\n",
    "    value_testCV = XCV_test.dot(b)\n",
    "    return [XCV_test,tCV_test,value_testCV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It stocks the data needed to improve computation time\n",
    "[linregCV,w_hatCV,XCV,tCV]=[[],[],[],[]]\n",
    "[XCV_test,tCV_test,value_testCV] = [[],[],[]]\n",
    "for k in range(10):\n",
    "    [linregCV1,w_hatCV1,XCV1,tCV1]= train(k)\n",
    "    [XCV_test1,tCV_test1,value_testCV1] = test(k)\n",
    "    i=0\n",
    "    for element in [linregCV,w_hatCV,XCV,tCV,XCV_test,tCV_test,value_testCV] :\n",
    "        element.append([linregCV1,w_hatCV1,XCV1,tCV1,XCV_test1,tCV_test1,value_testCV1][i])\n",
    "        i = i+1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It computes the mean squared error \n",
    "def RLSCV(k,l) :\n",
    "    #[linregCV,w_hatCV,XCV,tCV] = train(k) \n",
    "    #[XCV_test,tCV_test,value_testCV] = test(k)\n",
    "    theta = np.linalg.inv((XCV[k].transpose()).dot(XCV[k])-l*A).dot(XCV[k].transpose()).dot(tCV[k])\n",
    "    value = XCV_test[k].dot(theta)\n",
    "    EMS = ((value - tCV_test[k])**2).mean()\n",
    "    return EMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mean(liste) :\n",
    "    mean1=0\n",
    "    for k in range(len(liste)) :\n",
    "        mean1 = mean1 + liste[k]\n",
    "    mean1 = mean1/len(liste)\n",
    "    return mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#It computes the mean squarred error for the 10 splits of train data and take the mean for different regularization parameters\n",
    "RLSCVMean = []\n",
    "for l in range(1000):\n",
    "    RLSCVtmp = []\n",
    "    for k in range(10):\n",
    "        RLSCVtmp.append(RLSCV(k,0.01*l))\n",
    "    RLSCVMean.append(mean(RLSCVtmp))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(RLSCVMean)\n",
    "#plt.ylim(0,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value is \n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "best_l = 0.01*RLSCVMean.index(min(RLSCVMean))\n",
    "print(\"The best value is \" )\n",
    "print(best_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Compare the performance with the standard linear regression case, discussing possible reasons for any change in performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of the mean square error with the standard linear regression is 0.390235\n",
      "The value of the mean square error with the regularized linear regression is 0.390430\n",
      "The difference between this two values is -0.000195\n"
     ]
    }
   ],
   "source": [
    "print(\"The value of the mean square error with the standard linear regression is %f\" %(EMS))\n",
    "print(\"The value of the mean square error with the regularized linear regression is %f\" %(RLS(best_l)))\n",
    "print(\"The difference between this two values is %f\" %(EMS-RLS(best_l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best regularization parameter is near from zero, that is why their is not a big changement between the standard and the regularized linear regresion. In some cases, the standard method is better than the regularized one. This show an exemple of overfitting : by doing better on the train data, we do worse on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6 - Classification\n",
    "#### (a) Describe one limitation of using regression for this particular task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The regression is good when the information that we need is continuous, however, the quality can only be an integer value, so we can't use the regression in this case, we have to use the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Pick either Naive Bayes or KNN. Describe a positive and a negative feature of your classifier with respect to this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I chose KNN. I can use my benchmark to see what are the features that vary like the quality and the ones which have a lower influence on it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#It allows to found the feature which fit well or bad the quality\n",
    "a=max(benchmark_value)\n",
    "b=min(benchmark_value)\n",
    "print(benchmark_value.index(a))\n",
    "print(benchmark_value.index(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In almost all the cases, we can see that the \"residual sugar\" feature is a negative feature, because the quality does not depend a lot on it. Moreover, a positive feature is \"alcohol\" because the quality depends a lot on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Describe any data pre-processing that you suggest for this data and your chosen classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To apply a KNN classification, I need to compute a distance between the different wine, and, to do that, I need all the features to have the same weight - for exemple, the density feature would be disadvantaged a lot if we don't ponderate all the data. With that, I can compute the euclidian distance with the same weight for all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pond = []\n",
    "k=0\n",
    "pond_data = pd.read_csv('winequality-red.csv', sep = ';')\n",
    "for column in train_data :\n",
    "    if column != 'quality' :\n",
    "        pond.append(max(pond_data[column]) - min(pond_data[column]))\n",
    "        pond_data[column] = pond_data[column]/pond[k]\n",
    "        k=k+1\n",
    "del pond_data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (d) Implement your classifier and optimize its parameters. Make sure your optimization is clearly commented. Use classification accuracy as your figure of merit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data frame are too long to be read, so I have to work with lists\n",
    "k=0\n",
    "pond_data1 = []\n",
    "for column in pond_data :\n",
    "    pond_data2 = []\n",
    "    for l in range(len(pond_data)) :\n",
    "        pond_data2.append(pond_data[column][l])\n",
    "    pond_data1.append(pond_data2)\n",
    "    k += 1\n",
    "\n",
    "#computation of the euclidian distance :\n",
    "import math\n",
    "def eucldistance(i,j) :\n",
    "    sum = 0\n",
    "    for column in range(len(pond_data1)) :\n",
    "            sum = sum + (pond_data1[column][i] - pond_data1[column][j])**2\n",
    "    #for column in pond_data :\n",
    "    #    sum = sum + (pond_data[column][i] - pond_data[column][j])**2\n",
    "    return math.sqrt(sum)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# found the k nearest neighbors\n",
    "def KNNfound(i,K) :\n",
    "    eucl = []\n",
    "    near = []\n",
    "    train_index1 = train_index[:]\n",
    "    for j in train_index :\n",
    "        eucl.append(eucldistance(i,j))\n",
    "    eucl1 = eucl[:]\n",
    "    eucl.sort()\n",
    "    for k in range(K) : \n",
    "        near.append(train_index1[eucl1.index(eucl[k])])\n",
    "        # this line is to avoid the fact that the same line is taken two times \n",
    "        eucl1[eucl1.index(eucl[k])] = 10000\n",
    "    return near\n",
    "# found the quality of the k nearest neighbors\n",
    "def KNNquality(i,K) :\n",
    "    near = KNNfound(i,K)\n",
    "    qual = []\n",
    "    for k in range(K) :\n",
    "        qual.append(red_wine['quality'][near[k]]) \n",
    "    return qual\n",
    "# found the quality which appear the most\n",
    "def KNN(i,K) :\n",
    "    qual = KNNquality(i,K)\n",
    "    choice = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for k in range(K) :\n",
    "        choice[qual[k]] += 1\n",
    "    quality = choice.index(max(choice))\n",
    "    return quality\n",
    "# compute the accuracy\n",
    "def acc() :\n",
    "    count = 0\n",
    "    for k in range(len(test_index)) :\n",
    "        if pred[k] == red_wine['quality'][test_index[k]] :\n",
    "                   count += 1\n",
    "    return 100*count/len(test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the computation is done, I have first to optimize the parameters on the train data.\n",
    "To optimize the parameters, I will make a 10-fold CV on the train data. I can use again trainCV and the function choose_train made in part 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# found the k nearest neighbors\n",
    "def KNNfoundCV(i,K) :\n",
    "    eucl = []\n",
    "    near = []\n",
    "    train_indexes1 = []\n",
    "    train_indexes1 = [train_index[k] for k in train_indexes]\n",
    "    for j in train_indexes1 :\n",
    "        eucl.append(eucldistance(i,j))\n",
    "    for k in range(K) :\n",
    "        near.append(train_indexes1[eucl.index(min(eucl))])\n",
    "        eucl[eucl.index(min(eucl))] = 1000\n",
    "    return near\n",
    "# found the quality of the k nearest neighbors\n",
    "def KNNqualityCV(i,K) :\n",
    "    near = KNNfoundCV(i,K)\n",
    "    qual = []\n",
    "    for k in range(K) :\n",
    "        qual.append(red_wine['quality'][near[k]]) \n",
    "    return qual\n",
    "# found the quality which appear the most\n",
    "def KNNCV(i,K) :\n",
    "    qual = KNNqualityCV(i,K)\n",
    "    choice = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for k in range(K) :\n",
    "        choice[qual[k]] += 1\n",
    "    quality = choice.index(max(choice))\n",
    "    return quality\n",
    "# compute the accuracy\n",
    "def accCV() :\n",
    "    count = 0\n",
    "    for k in range(len(test_indexes)) :\n",
    "        if predCV[k] == red_wine['quality'][train_index[test_indexes[k]]] :\n",
    "                   count += 1\n",
    "    return 100*count/len(test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 1 , accuracy = 61.204954954954964 %\n",
      "With k = 2 , accuracy = 56.82432432432434 %\n",
      "With k = 3 , accuracy = 57.461711711711715 %\n",
      "With k = 4 , accuracy = 57.358108108108105 %\n",
      "With k = 5 , accuracy = 58.17567567567568 %\n"
     ]
    }
   ],
   "source": [
    "# make the optimization on the train data\n",
    "test_index.sort()\n",
    "K=5\n",
    "accur = []\n",
    "for k in range(1,K+1) :\n",
    "    accu = []\n",
    "    for l in range(10):\n",
    "        [train_datas, test_datas, train_indexes,test_indexes] = choose_train(l)\n",
    "        predCV = []\n",
    "        for i in [train_index[k] for k in test_indexes] :\n",
    "            predCV.append(KNNCV(i,k))\n",
    "        accu.append(accCV())\n",
    "    accur.append(mean(accu))\n",
    "    print('With k =',k,', accuracy =',mean(accu),'%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best number of neighbor is 1\n"
     ]
    }
   ],
   "source": [
    "K = accur.index(max(accur)) + 1\n",
    "print('The best number of neighbor is',K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With k = 1 , accuracy = 59.791666666666664 %\n"
     ]
    }
   ],
   "source": [
    "# make the classification on the test data\n",
    "test_index.sort()\n",
    "pred = []\n",
    "for l in test_index :\n",
    "    pred.append(KNN(l,K))\n",
    "print('With k =',K,', accuracy =',acc(),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (e) Display the confusion matrix on the text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "confmat = np.eye(max(t)-min(t)+1)\n",
    "count = 0\n",
    "compare = np.eye(len(test_index),2)\n",
    "for k in range(len(test_index)) :\n",
    "    compare[k][0]=red_wine['quality'][test_index[k]]\n",
    "    compare[k][1]= pred[k]\n",
    "#compare = np.sort(compare,0)\n",
    "for l in range(int(min(t)),int(max(t))+1) :\n",
    "    for m in range(int(min(t)),int(max(t)+1)) :\n",
    "        count = 0\n",
    "        for k in range(len(compare)):\n",
    "            if int(compare[k][0]) == l and int(compare[k][1]) == m :\n",
    "                count += 1\n",
    "        confmat[l-int(min(t))][m-int(min(t))] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confidence matrix is :\n",
      "[[   0.    2.    2.    0.    0.    0.]\n",
      " [   0.    1.    8.    5.    0.    0.]\n",
      " [   0.    8.  141.   47.    5.    0.]\n",
      " [   0.    3.   58.  112.   21.    0.]\n",
      " [   0.    1.    6.   21.   32.    3.]\n",
      " [   0.    0.    0.    2.    1.    1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"the confidence matrix is :\")\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f) Discuss the performance and suggest a way in which they could be improved "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The performance is quite good. Indeed, while the accuracy is not very good (around 60 percent), the predicted quality is almost every time near from the actual quality. As expected in the question 3, the qualities 5,6 and 7 are more easy to find, because we can see in the matrix that we find the good quality in many cases. But this performance is far to be perfect. Indeed, to improve this classification, we could, insteed of choosing the quality which has the more of occurence in the k neighbors, we can divide the chances to choose one quality by the distance to this point. As instance, if, for one wine, the quality of the nearest neighbors is [3,3,2,2,2], and the distance to this neighbors is [0.5,1,2,4,6].With the method that I used, I would choose the quality 2 for the wine, while if I choose the other method, the quality 3 has a score of 1/0.5+1/1 = 3, while the quality 2 has a score of 1/2+1/4+1/6=0.92. The score of the quality 3 is better than the score of 2, so the quality chosen is 3 in this case. An other way to improve the performance could be to ponderate the feateures depending on if they are good or bad features insteed of using the euclidian distance. For example, the \"residual sugar\" feature would have a weight of 0.5 in the sume while \"alcohol\" would have 2. So the good features would be more important than the bad features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
